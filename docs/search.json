[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "My passion for ecology stems from my heritage. I am an Alaskan Native and a member of the Native Village of False Pass. However, I was raised on the Swinomish Reservation in Northwestern Washington State, a tribe at the forefront of climate change adaptation. My appreciation for nature undoubtedly came from the beauty and cultural significance of my homelands.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRare plant monitoring in North Cascades (above) and Olympic National Parks (below)\n\n\nIn undergrad, I earned a BS in Environmental Science and Resource Management from the University of Washington (2019). Members of my community taught me early on the importance of environmental problem solving and pursuing a career in the environment is my way of continuing the legacy of indigenous stewardship.\nMy undergraduate research included work with UW’s hydro-biogeochemistry lab studying methane emissions from permafrost thaw bogs, and a capstone project conducted in Costa Rica’s cloud forest examining the relationship between mycorrhizal abundance and soil organic carbon. After graduation, I worked alongside the National Parks Service as a field ecologist with UW Botanic Gardens’ RareCare program. My small team and I utilized GIS and field techniques to establish long-term monitoring plots for rare and endangered alpine plants throughout Washington’s Olympic and North Cascades National Parks.\nThrough my experiences with RareCare, I found myself increasingly drawn to the power held at the intersection of ecology and data science. Particularly how data can contribute to wildlife conservation, the protection of culturally significant species, and inclusivity in STEM.\n\n\n\nAs a graduate student, I am growing exponentially both personally and professionally. I am enjoying developing my coding skills, mostly in R and Python, and learning how my diverse experiences uniquely qualify me for environmental problem solving.\nTake a look at my work to see recent projects that I’ve been working on.\n\n\n\nWhen my head is not buried in code, you can find me pursuing my many other interests:\n\nIndoors, I will probably be bead weaving, cooking, or re-reading my all time favorite book (Braiding Sweetgrass by Robin Wall Kimmerer)\nOutdoors, you can catch me biking, hiking, climbing, swimming in all the alpine lakes, and snowboarding like an amateur\nOtherwise, find me tinkering on the pet project, my self-built campervan (aka, Trashcan the Van). In 2021 I converted an empty cargo van into a cozy, off-grid, home on wheels with no experience and very limited tools. I’m pretty dang proud of the thing, and my dog Tahoma and I have taken Trashcan over 10,000 miles, traveled to 30 states, and 3 countries. Let me know if you’d like to chat DIY solar systems, woodworking tips, or road-trip planning Face Smile\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy second home (on-wheels), Trashcan the Van, parked among the Giant Cardons in Baja, MX"
  },
  {
    "objectID": "about.html#the-lore",
    "href": "about.html#the-lore",
    "title": "about",
    "section": "",
    "text": "My passion for ecology stems from my heritage. I am an Alaskan Native and a member of the Native Village of False Pass. However, I was raised on the Swinomish Reservation in Northwestern Washington State, a tribe at the forefront of climate change adaptation. My appreciation for nature undoubtedly came from the beauty and cultural significance of my homelands.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRare plant monitoring in North Cascades (above) and Olympic National Parks (below)\n\n\nIn undergrad, I earned a BS in Environmental Science and Resource Management from the University of Washington (2019). Members of my community taught me early on the importance of environmental problem solving and pursuing a career in the environment is my way of continuing the legacy of indigenous stewardship.\nMy undergraduate research included work with UW’s hydro-biogeochemistry lab studying methane emissions from permafrost thaw bogs, and a capstone project conducted in Costa Rica’s cloud forest examining the relationship between mycorrhizal abundance and soil organic carbon. After graduation, I worked alongside the National Parks Service as a field ecologist with UW Botanic Gardens’ RareCare program. My small team and I utilized GIS and field techniques to establish long-term monitoring plots for rare and endangered alpine plants throughout Washington’s Olympic and North Cascades National Parks.\nThrough my experiences with RareCare, I found myself increasingly drawn to the power held at the intersection of ecology and data science. Particularly how data can contribute to wildlife conservation, the protection of culturally significant species, and inclusivity in STEM."
  },
  {
    "objectID": "about.html#the-work",
    "href": "about.html#the-work",
    "title": "about",
    "section": "",
    "text": "As a graduate student, I am growing exponentially both personally and professionally. I am enjoying developing my coding skills, mostly in R and Python, and learning how my diverse experiences uniquely qualify me for environmental problem solving.\nTake a look at my work to see recent projects that I’ve been working on."
  },
  {
    "objectID": "about.html#the-play",
    "href": "about.html#the-play",
    "title": "about",
    "section": "",
    "text": "When my head is not buried in code, you can find me pursuing my many other interests:\n\nIndoors, I will probably be bead weaving, cooking, or re-reading my all time favorite book (Braiding Sweetgrass by Robin Wall Kimmerer)\nOutdoors, you can catch me biking, hiking, climbing, swimming in all the alpine lakes, and snowboarding like an amateur\nOtherwise, find me tinkering on the pet project, my self-built campervan (aka, Trashcan the Van). In 2021 I converted an empty cargo van into a cozy, off-grid, home on wheels with no experience and very limited tools. I’m pretty dang proud of the thing, and my dog Tahoma and I have taken Trashcan over 10,000 miles, traveled to 30 states, and 3 countries. Let me know if you’d like to chat DIY solar systems, woodworking tips, or road-trip planning Face Smile\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy second home (on-wheels), Trashcan the Van, parked among the Giant Cardons in Baja, MX"
  },
  {
    "objectID": "blog-posts/chinook-harvest/index.html",
    "href": "blog-posts/chinook-harvest/index.html",
    "title": "Chinook Salmon Harvest",
    "section": "",
    "text": "In the Aleutians, summer is the highly anticipated “Sockeye (aanux̂)1 Season”. For many of the Indigenous (Unangan) residents, fishing is not only a way to make a living - it is the way to live. Fishing provides income, food to sustain a family for the year, and cultural connection to our land, community, and ancestors.\n\n\n\n\n\n\n\n\n\n\n\n\nJars of salmon were a regular find in my care packages.\nPhoto credits: Danielle Ringer\n\nFor me, fall is the highly anticipated “Care Package Season”. When there is enough, my family always shares (udigdada) the bounty. Down in the mainland, annual care packages filled with Alaska’s summer harvests keep me connected to my Aleutian family and culture. Salmonberry (alagnax̂) and mossberry (qaayux̂) jelly, pickled putchkis (saaqudax̂), dried salmon and halibut (udax̂), smoked salmon (qam dimiĝii), and if I’m lucky caribou (itx̂ayax̂) are tastes of home in the Aleutians delivered to me in the Pacific Northwest. We turn these ingredients into traditional dishes like fish pie (piruugax̂) and stewed caribou and gravy over rice (Aluutagaaq), and we make fry bread (alaadikax̂) to go along with them. While Salmon is abundant in these gifts, the prized Chinook (chaguchax̂) rarely makes its way to us down south.\nBecause of my Aleutian ties, I am innately curious about human-salmon systems. Sam Cisk, data science educator (and mentor for building this website), pointed me towards the State of Alaska People and Salmon Project (SASAP). The project included an NCEAS working group data team, and they published open-source, up-to-date datasets regarding people and salmon throughout Alaska. I think that this project was wildly cool, and work like this is what keeps me inpired while pursuing an environmental data science career!\nIn this analysis for my final project for EDS 222 - Statistics for Environmental Data Science, I use a SASAP dataset to explore the relationship between fishing sector and harvest of the beloved Chinook salmon. Read on to learn more about my analysis, or see my GitHub repository!\n\n\n\n\n\n\n\n\n\n\n\n\nScenery in the Aleutians. Photo credits: Aleutian Island Waterfowlers\n\nSalmon are crucial to the health and cultural wellbeing of Aleut/Unangan communities along the eastern Aleutians and Alaskan Peninsula. Of the 5 Pacific salmon species, Chinook salmon hold particular cultural significance. They are also the largest, and fetch one of the highest values per pound on the commercial market 2.\nFor Aleutian communities, there is very little separation between commercial and subsistence fishing activities. Often, subsistence fish are retained to fill freezers as “homepack” from commercial harvests 3. This makes understanding participation in these fishing sectors very complex.\nThe State of Alaska Salmon and People Project (SASAP) is a collaboration of Indigenous and non-Indigenous researchers, scholars and community leaders working to produce and share integrated, accurate, and up-to-date information on Alaska’s salmon and people systems. They compiled 125 data sets into an open-source data portal that makes relevant salmon information accessible and usable by Alaskans wishing to advocate on their own behalf for a better salmon future. In recognition of the complex relationship between commercial and subsistence harvests, they uniquely derive estimated subsistence harvest from a combination of subsistence permit returns and post-season household survey data.\nUsing their dataset, Harvest of Salmon across Commercial, Subsistence, Personal Use, and Sport Fish sectors, Alaska, 1995-2016, I aim to explore how Chinook salmon harvest varies between commercial and subsistence fishing sectors.\n\n\n\nI am using a dataset from the SASAP data portal that counts harvest of the 5 Pacific salmon species across fishing sectors in Alaska from 1995-2016. The time range for the data starts in 1975, but it isn’t until 1995 that we see all 4 sectors represented in the data.\n\nAccess: https://knb.ecoinformatics.org/view/doi%3A10.5063%2FF1HM56Q3\nFile: Harvest_All_Sectors.csv\nCitation: Jeanette Clark, & Alaska Department Fish Game, Division Commercial Fisheries Alaska Department Fish Game, Division Sport Fish Alaska Department Fish Game, Division of and of of and of of and of Subsistence. (2019). Harvest of Salmon across Commercial, Subsistence, Personal Use, and Sport Fish sectors, Alaska, 1995-2016. Knowledge Network for Biocomplexity. doi:10.5063/F1HM56Q3.\n\n\n\n\nConsidering the cultural significance that Chinook salmon hold in Unangan communities, it is possible that the proportion of Chinook salmon harvested will be greater in the subsistence sector than in the commercial sector. However, there is also a monetary incentive for harvesting Chinook for commercial purposes, as they are the largest Pacific species and fetch a high value on the market.\nDespite their high commercial value, I hypothesize that the proportion of Chinook salmon harvested is greater in the subsistence sector than the commercial sector.\nTo explore this hypothesis, I use a randomization test to explore the question:\nIs the proportion of Chinook salmon harvested greater in the subsistence sector than the commercial sector?\n\nNull hypothesis: The proportion of Chinook salmon harvested is not greater in the subsistence sector than the commercial sector.\nAlternative hypothesis: The proportion of Chinook salmon harvested is greater in the subsistence sector than the commercial sector.\n\n\n\n\n\n\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# Load data\nharvest &lt;- read_csv(\"Harvest_All_Sectors.csv\")\n\n\n\n\nThe data includes harvest counts for all Alaska regions. For this analysis, I am only interested in the Alaska Peninsula and Aleutian Islands:\n\n# Filter harvest data to the Alaska Peninsula and Aleutian Islands\napai_harvest &lt;- harvest |&gt;\n  filter(SASAP.Region == \"Alaska Peninsula and Aleutian Islands\")\n\nNext, I want to categorize sector into two groups: subsistence and commercial. On the ground, personal use and subsistence catches are nearly identical in harvest methods and use. The personal use sector was created in response to the enactment of the state’s subsistence priority law, which precluded some individuals from participating in customary and traditional subsistence fisheries because the stocks they fish are not classified as customary and traditional use stocks 4. Because of this, I will group personal use into the subsistence category.\n\n# Replace all \"Personal Use\" with \"Subsistence\"\napai_harvest$sector &lt;- str_replace_all(apai_harvest$sector, \"Personal Use\", \"Subsistence\")\n\n# Check that Personal Use is no longer in dataset\nunique(apai_harvest$sector)\n\n[1] \"Commercial\"  \"Sport Fish\"  \"Subsistence\"\n\n\nI want to compare Chinook salmon to all other species. By grouping all other salmon species into one group, I will be able to calculate total harvest for Chinook and other species by sector and year.\nFrom 1975-1984, there is only data for commercial harvest. I want to only include years that have data for both the commercial and subsistence sectors, so I will filter the data to 1985-2016. Lastly, I will finish my data cleaning by filtering down to the two sectors of interest, Subsistence and Commercial.\n\n# Subset data to harvest of Chinook salmon and other salmon species in the 2 sectors from 1985-2016\nchinook_harvest &lt;- apai_harvest |&gt;\n  mutate(species = ifelse(species == \"chinook\", \"chinook\", \"other\")) |&gt;\n  filter((sector == \"Commercial\") | (sector == \"Subsistence\")) |&gt;\n  filter(year &gt;= 1985 & year &lt;= 2016) |&gt;\n  group_by(year, sector, species) |&gt;\n  summarize(harvest = sum(harvest, na.rm = TRUE), .groups = \"drop\")\n\n\n\n\nFirst, I take a look at the distribution of species harvest between the two sectors:\n\n\nCode\n# Make boxplot of harvest distributions by species and sector\nggplot(chinook_harvest, aes(x = sector, y = harvest, fill = species)) +\n  geom_boxplot() +\n  facet_wrap(~sector, scale = \"free\") +\n  scale_fill_brewer(\"Species\", palette = \"Pastel1\") +\n  labs(y = \"Number of individuals harvested\",\n       x = \"Fishing Sector\",\n       title = \"Distribution of species harvested by sector\") +\n  theme_bw()\n\n\n\n\n\nThis plot shows the distribution of total harvest for Chinook and other salmon species between the subsistence and commercial fishing sectors from 1985-2016\n\n\n\n\nSince the difference in magnitude of Chinook harvest compared to all other species is so large, it makes comparing the distributions difficult to interpret. To normalize the differences for the sake of visualization, I log transform harvest:\n\n\nCode\n# Remake the same boxplot but log transform harvest for ease of visualization\nggplot(chinook_harvest, aes(x = sector, y = log(harvest), fill = species)) +\n  geom_boxplot() +\n  facet_wrap(~sector, scale = \"free\") +\n  scale_fill_brewer(\"Species\", palette = \"Pastel1\") +\n  labs(y = \"Log number of individuals harvested\",\n       x = \"Fishing Sector\",\n       title = \"Distribution of species harvested by sector - Log transformed\") +\n  theme_bw()\n\n\n\n\n\nThis plot shows the distribution of total harvest (log transformed) for Chinook and other salmon species between the subsistence and commercial fishing sectors from 1985-2016\n\n\n\n\nI am also interested to see the proportion of Chinook of the total harvest between sectors:\n\n\nCode\n# Make bar plot showing proportion of Chinook harvested\nggplot(chinook_harvest, aes(x = sector, y = harvest, fill = factor(species))) +\n  geom_col() +\n  facet_wrap(~sector, scale = \"free\") +\n  scale_fill_brewer(\"Species\", palette = \"Pastel1\") +\n  labs( x = \"Fishing Sector\", \n        y = \"Number of individuals harvested\",  \n        title = \"Total Chinook Harvest by Sector\") +\n  theme_minimal()\n\n\n\n\n\nThis plot shows the proportion of Chinook salmon of the total salmon harvest from 1985-2016 in the subsistence and commercial fishing sectors\n\n\n\n\nThe proportion of Chinook salmon harvested is a very small fraction of the whole. This makes sense, as Chinook abundance is relatively low compared to overall salmon abundance in the North Pacific 5. This makes the differences between sectors challenging to visually interpret. However, it seems that there is a higher proportion of Chinook harvested in the subsistence sector. It is important to notice the difference in the y-axes across all of these plots.\n\n\n\nI choose a randomization test for this analysis because it is a simple and straightforward way to compare the difference in proportions between two categories in my data. Since randomization tests make no underlying assumptions about the data, I do not need to check for normality before jumping in.\nStep 1: State the null and alternative hypotheses:\n\nNull hypothesis: The proportion of Chinook salmon harvested is not greater in the subsistence sector than the commercial sector.\nAlternative hypothesis: The proportion of Chinook salmon harvested is greater in the subsistence sector than the commercial sector.\n\nStep 2: Calculate the point statistic:\nThe relevant sample statistic for my hypothesis is a difference in proportions between Chinook total harvest / other total harvest in the commercial and subsistence sectors.\n\n# Find chinook proportion of total harvest in each sector\nchinook_prop &lt;- chinook_harvest |&gt;\n  group_by(species, sector) |&gt;\n  summarise(species_harvest = sum(harvest, na.rm = TRUE), .groups = \"drop\") |&gt;\n  group_by(sector) |&gt;\n  summarize(proportion = species_harvest[species == \"chinook\"] / sum(species_harvest))\n\n\n\nCode\n# Display percent of Chinook salmon in each harvest in a table\nchinook_prop |&gt;\n  mutate(proportion = round(proportion*100, 2)) |&gt;\n  kbl(col.names = c(\"Fishing sector\", \"Percent Chinook salmon of total harvest\"),\n      caption = \"Table showing the percent of the total harvest that is Chinook salmon from 1985-2016. Chinook salmon made up 1.41% of the total salmon harvest in the subsistence sector, while Chinook only made up 0.14% of the total harvest in the commercial sector.\") |&gt;\n  kable_styling(full_width = FALSE, \n                bootstrap_options = c(\"striped\", \"hover\"),\n                position = \"left\")\n\n\n\nTable showing the percent of the total harvest that is Chinook salmon from 1985-2016. Chinook salmon made up 1.41% of the total salmon harvest in the subsistence sector, while Chinook only made up 0.14% of the total harvest in the commercial sector.\n\n\nFishing sector\nPercent Chinook salmon of total harvest\n\n\n\n\nCommercial\n0.14\n\n\nSubsistence\n1.41\n\n\n\n\n\n\n\n\n# Calculate difference in proportions between sectors\npe &lt;- chinook_prop$proportion[2] - chinook_prop$proportion[1]\npe\n\n[1] 0.01275766\n\n\nThe difference in Chinook salmon harvested as a percentage of the overall harvest between subsistence and commercial sectors is 1.28%.\nStep 3: Quantify the uncertainty\nUse randomization to simulate the distribution of the sample statistic under the null hypothesis.\n\n# For reproducability\nset.seed(2222)\n\n# Randomization test\nnull_dist &lt;- replicate(1000, {\n  chinook_prop &lt;- chinook_harvest |&gt;\n    mutate(sector = sample(sector, n())) |&gt;  # Shuffling happening here\n    group_by(species, sector) |&gt;\n    summarise(species_harvest = sum(harvest, na.rm = TRUE), .groups = \"drop\") |&gt;\n    group_by(sector) |&gt;\n    summarize(proportion = species_harvest[species == \"chinook\"] / sum(species_harvest))\n  \n  # Calculate difference in proportions between sectors\n  pe &lt;- chinook_prop$proportion[2] - chinook_prop$proportion[1]\n  pe\n})\n\n# Visualize null distribution\nggplot(tibble(null_dist), aes(null_dist)) +\n  geom_histogram(bins = 20, color = \"#B8CCE1\", fill = NA, linewidth = 1) +\n  geom_vline(xintercept = pe, color = \"#F0B7B0\", linewidth = 1) +\n  geom_text(aes(x = 0.0105, y = 310, label = paste(\"True Point Estimate\")), \n            color = \"#F0B7B0\", size = 4) +\n  labs(x = \"Null distribution\",\n       y = \"Count\",\n       title = \"Simulated distribution of the sample statistic under the null hypothesis\") +\n  theme_bw()\n\n\n\n\nThis plot shows the simulated distribution of the difference in proportions under the null hypothesis. The pink line shows the true difference in proportions of the sample.\n\n\n\n\nUnder the null hypothesis, the sample statistic is normally distributed and centered around 0. The true point statistic from the data is out to the right.\nStep 4: Calculate probability of the point estimate under the null\n\n# Calculate the p-value\npval &lt;- sum((null_dist) &gt; (pe)) / length(null_dist)\nprint(pval)\n\n[1] 0\n\n\nThe p-value 0 is less than the threshold, 0.05. So, I am able to reject the null hypothesis and say that there is a 0% chance that the relationship is due to random chance. I find that the proportion of Chinook salmon harvested is in fact greater in the subsistence sector than the commercial sector.\n\n\n\n\nLimitations:\n\nSubsistence harvest data is an estimate based on household surveys and permit returns. It is extremely difficult to obtain reliable subsistence harvest data in these small communities.\nThe data I use for running the randomization test is highly aggregated, missing nuance that may exist on a finer scale.\n\nThis is an extremely simplified analysis of a very complex system. The results I found, though an interesting starting point for further analysis, should be interpreted for educational purposes only. This workflow was created as the final assignment for the graduate course EDS 222: Statistics for Environmental Data Science in the MEDS program at the Bren School of Environmental Science & Management. Throughout my project, it was my goal to apply concepts and techniques learned in class to a question about a real-world system, not to necessarily draw any reliable scientific conclusions from the study.\nThat said, my results have piqued my interest. What is this suggesting about the way Aleutian communities prioritize cultural significance and monetary incentive? Are we seeing the results of fisherman preferences or fishery sector escapement counts and bag limits? Would I see the same results if I had considered the proportion of Chinook harvested in these fishing sectors over time? What if I added other parts of the system, such as declining Chinook abundance, or Chinook escapement counts from subsistence fisheries? The questions are endless, and the data that SASAP provided is quite comprehensive. Further investigation using these datasets could yield some extremely interesting results, with potentially high value for Unangan people and Aleutian fishing communities.\nNote:\nI switch between talking about Unangan people and the broader Aleutian fishing communities throughout this analysis. Both Indigenous and non-Indigenous residents of the Aleutian Islands and Alaskan Peninsula participate in commercial and subsistence fishing activities, with Indigenous fishers only making up a small portion of the population. Drawing on my personal experience in these tight-knit communities, cultural practices regarding salmon carry across Indigenous and non-Indigenous members alike. Because of this, I take liberties applying “cultural significance” to all community members in the region.\n\nThank you!\n\n\n\n\n\n\n\n\n\n\n\nImage credits: Eric Jablonowski"
  },
  {
    "objectID": "blog-posts/chinook-harvest/index.html#background",
    "href": "blog-posts/chinook-harvest/index.html#background",
    "title": "Chinook Salmon Harvest",
    "section": "",
    "text": "Scenery in the Aleutians. Photo credits: Aleutian Island Waterfowlers\n\nSalmon are crucial to the health and cultural wellbeing of Aleut/Unangan communities along the eastern Aleutians and Alaskan Peninsula. Of the 5 Pacific salmon species, Chinook salmon hold particular cultural significance. They are also the largest, and fetch one of the highest values per pound on the commercial market 2.\nFor Aleutian communities, there is very little separation between commercial and subsistence fishing activities. Often, subsistence fish are retained to fill freezers as “homepack” from commercial harvests 3. This makes understanding participation in these fishing sectors very complex.\nThe State of Alaska Salmon and People Project (SASAP) is a collaboration of Indigenous and non-Indigenous researchers, scholars and community leaders working to produce and share integrated, accurate, and up-to-date information on Alaska’s salmon and people systems. They compiled 125 data sets into an open-source data portal that makes relevant salmon information accessible and usable by Alaskans wishing to advocate on their own behalf for a better salmon future. In recognition of the complex relationship between commercial and subsistence harvests, they uniquely derive estimated subsistence harvest from a combination of subsistence permit returns and post-season household survey data.\nUsing their dataset, Harvest of Salmon across Commercial, Subsistence, Personal Use, and Sport Fish sectors, Alaska, 1995-2016, I aim to explore how Chinook salmon harvest varies between commercial and subsistence fishing sectors."
  },
  {
    "objectID": "blog-posts/chinook-harvest/index.html#data-details",
    "href": "blog-posts/chinook-harvest/index.html#data-details",
    "title": "Chinook Salmon Harvest",
    "section": "",
    "text": "I am using a dataset from the SASAP data portal that counts harvest of the 5 Pacific salmon species across fishing sectors in Alaska from 1995-2016. The time range for the data starts in 1975, but it isn’t until 1995 that we see all 4 sectors represented in the data.\n\nAccess: https://knb.ecoinformatics.org/view/doi%3A10.5063%2FF1HM56Q3\nFile: Harvest_All_Sectors.csv\nCitation: Jeanette Clark, & Alaska Department Fish Game, Division Commercial Fisheries Alaska Department Fish Game, Division Sport Fish Alaska Department Fish Game, Division of and of of and of of and of Subsistence. (2019). Harvest of Salmon across Commercial, Subsistence, Personal Use, and Sport Fish sectors, Alaska, 1995-2016. Knowledge Network for Biocomplexity. doi:10.5063/F1HM56Q3."
  },
  {
    "objectID": "blog-posts/chinook-harvest/index.html#hypothesis",
    "href": "blog-posts/chinook-harvest/index.html#hypothesis",
    "title": "Chinook Salmon Harvest",
    "section": "",
    "text": "Considering the cultural significance that Chinook salmon hold in Unangan communities, it is possible that the proportion of Chinook salmon harvested will be greater in the subsistence sector than in the commercial sector. However, there is also a monetary incentive for harvesting Chinook for commercial purposes, as they are the largest Pacific species and fetch a high value on the market.\nDespite their high commercial value, I hypothesize that the proportion of Chinook salmon harvested is greater in the subsistence sector than the commercial sector.\nTo explore this hypothesis, I use a randomization test to explore the question:\nIs the proportion of Chinook salmon harvested greater in the subsistence sector than the commercial sector?\n\nNull hypothesis: The proportion of Chinook salmon harvested is not greater in the subsistence sector than the commercial sector.\nAlternative hypothesis: The proportion of Chinook salmon harvested is greater in the subsistence sector than the commercial sector."
  },
  {
    "objectID": "blog-posts/chinook-harvest/index.html#analysis",
    "href": "blog-posts/chinook-harvest/index.html#analysis",
    "title": "Chinook Salmon Harvest",
    "section": "",
    "text": "# Load libraries\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# Load data\nharvest &lt;- read_csv(\"Harvest_All_Sectors.csv\")\n\n\n\n\nThe data includes harvest counts for all Alaska regions. For this analysis, I am only interested in the Alaska Peninsula and Aleutian Islands:\n\n# Filter harvest data to the Alaska Peninsula and Aleutian Islands\napai_harvest &lt;- harvest |&gt;\n  filter(SASAP.Region == \"Alaska Peninsula and Aleutian Islands\")\n\nNext, I want to categorize sector into two groups: subsistence and commercial. On the ground, personal use and subsistence catches are nearly identical in harvest methods and use. The personal use sector was created in response to the enactment of the state’s subsistence priority law, which precluded some individuals from participating in customary and traditional subsistence fisheries because the stocks they fish are not classified as customary and traditional use stocks 4. Because of this, I will group personal use into the subsistence category.\n\n# Replace all \"Personal Use\" with \"Subsistence\"\napai_harvest$sector &lt;- str_replace_all(apai_harvest$sector, \"Personal Use\", \"Subsistence\")\n\n# Check that Personal Use is no longer in dataset\nunique(apai_harvest$sector)\n\n[1] \"Commercial\"  \"Sport Fish\"  \"Subsistence\"\n\n\nI want to compare Chinook salmon to all other species. By grouping all other salmon species into one group, I will be able to calculate total harvest for Chinook and other species by sector and year.\nFrom 1975-1984, there is only data for commercial harvest. I want to only include years that have data for both the commercial and subsistence sectors, so I will filter the data to 1985-2016. Lastly, I will finish my data cleaning by filtering down to the two sectors of interest, Subsistence and Commercial.\n\n# Subset data to harvest of Chinook salmon and other salmon species in the 2 sectors from 1985-2016\nchinook_harvest &lt;- apai_harvest |&gt;\n  mutate(species = ifelse(species == \"chinook\", \"chinook\", \"other\")) |&gt;\n  filter((sector == \"Commercial\") | (sector == \"Subsistence\")) |&gt;\n  filter(year &gt;= 1985 & year &lt;= 2016) |&gt;\n  group_by(year, sector, species) |&gt;\n  summarize(harvest = sum(harvest, na.rm = TRUE), .groups = \"drop\")\n\n\n\n\nFirst, I take a look at the distribution of species harvest between the two sectors:\n\n\nCode\n# Make boxplot of harvest distributions by species and sector\nggplot(chinook_harvest, aes(x = sector, y = harvest, fill = species)) +\n  geom_boxplot() +\n  facet_wrap(~sector, scale = \"free\") +\n  scale_fill_brewer(\"Species\", palette = \"Pastel1\") +\n  labs(y = \"Number of individuals harvested\",\n       x = \"Fishing Sector\",\n       title = \"Distribution of species harvested by sector\") +\n  theme_bw()\n\n\n\n\n\nThis plot shows the distribution of total harvest for Chinook and other salmon species between the subsistence and commercial fishing sectors from 1985-2016\n\n\n\n\nSince the difference in magnitude of Chinook harvest compared to all other species is so large, it makes comparing the distributions difficult to interpret. To normalize the differences for the sake of visualization, I log transform harvest:\n\n\nCode\n# Remake the same boxplot but log transform harvest for ease of visualization\nggplot(chinook_harvest, aes(x = sector, y = log(harvest), fill = species)) +\n  geom_boxplot() +\n  facet_wrap(~sector, scale = \"free\") +\n  scale_fill_brewer(\"Species\", palette = \"Pastel1\") +\n  labs(y = \"Log number of individuals harvested\",\n       x = \"Fishing Sector\",\n       title = \"Distribution of species harvested by sector - Log transformed\") +\n  theme_bw()\n\n\n\n\n\nThis plot shows the distribution of total harvest (log transformed) for Chinook and other salmon species between the subsistence and commercial fishing sectors from 1985-2016\n\n\n\n\nI am also interested to see the proportion of Chinook of the total harvest between sectors:\n\n\nCode\n# Make bar plot showing proportion of Chinook harvested\nggplot(chinook_harvest, aes(x = sector, y = harvest, fill = factor(species))) +\n  geom_col() +\n  facet_wrap(~sector, scale = \"free\") +\n  scale_fill_brewer(\"Species\", palette = \"Pastel1\") +\n  labs( x = \"Fishing Sector\", \n        y = \"Number of individuals harvested\",  \n        title = \"Total Chinook Harvest by Sector\") +\n  theme_minimal()\n\n\n\n\n\nThis plot shows the proportion of Chinook salmon of the total salmon harvest from 1985-2016 in the subsistence and commercial fishing sectors\n\n\n\n\nThe proportion of Chinook salmon harvested is a very small fraction of the whole. This makes sense, as Chinook abundance is relatively low compared to overall salmon abundance in the North Pacific 5. This makes the differences between sectors challenging to visually interpret. However, it seems that there is a higher proportion of Chinook harvested in the subsistence sector. It is important to notice the difference in the y-axes across all of these plots.\n\n\n\nI choose a randomization test for this analysis because it is a simple and straightforward way to compare the difference in proportions between two categories in my data. Since randomization tests make no underlying assumptions about the data, I do not need to check for normality before jumping in.\nStep 1: State the null and alternative hypotheses:\n\nNull hypothesis: The proportion of Chinook salmon harvested is not greater in the subsistence sector than the commercial sector.\nAlternative hypothesis: The proportion of Chinook salmon harvested is greater in the subsistence sector than the commercial sector.\n\nStep 2: Calculate the point statistic:\nThe relevant sample statistic for my hypothesis is a difference in proportions between Chinook total harvest / other total harvest in the commercial and subsistence sectors.\n\n# Find chinook proportion of total harvest in each sector\nchinook_prop &lt;- chinook_harvest |&gt;\n  group_by(species, sector) |&gt;\n  summarise(species_harvest = sum(harvest, na.rm = TRUE), .groups = \"drop\") |&gt;\n  group_by(sector) |&gt;\n  summarize(proportion = species_harvest[species == \"chinook\"] / sum(species_harvest))\n\n\n\nCode\n# Display percent of Chinook salmon in each harvest in a table\nchinook_prop |&gt;\n  mutate(proportion = round(proportion*100, 2)) |&gt;\n  kbl(col.names = c(\"Fishing sector\", \"Percent Chinook salmon of total harvest\"),\n      caption = \"Table showing the percent of the total harvest that is Chinook salmon from 1985-2016. Chinook salmon made up 1.41% of the total salmon harvest in the subsistence sector, while Chinook only made up 0.14% of the total harvest in the commercial sector.\") |&gt;\n  kable_styling(full_width = FALSE, \n                bootstrap_options = c(\"striped\", \"hover\"),\n                position = \"left\")\n\n\n\nTable showing the percent of the total harvest that is Chinook salmon from 1985-2016. Chinook salmon made up 1.41% of the total salmon harvest in the subsistence sector, while Chinook only made up 0.14% of the total harvest in the commercial sector.\n\n\nFishing sector\nPercent Chinook salmon of total harvest\n\n\n\n\nCommercial\n0.14\n\n\nSubsistence\n1.41\n\n\n\n\n\n\n\n\n# Calculate difference in proportions between sectors\npe &lt;- chinook_prop$proportion[2] - chinook_prop$proportion[1]\npe\n\n[1] 0.01275766\n\n\nThe difference in Chinook salmon harvested as a percentage of the overall harvest between subsistence and commercial sectors is 1.28%.\nStep 3: Quantify the uncertainty\nUse randomization to simulate the distribution of the sample statistic under the null hypothesis.\n\n# For reproducability\nset.seed(2222)\n\n# Randomization test\nnull_dist &lt;- replicate(1000, {\n  chinook_prop &lt;- chinook_harvest |&gt;\n    mutate(sector = sample(sector, n())) |&gt;  # Shuffling happening here\n    group_by(species, sector) |&gt;\n    summarise(species_harvest = sum(harvest, na.rm = TRUE), .groups = \"drop\") |&gt;\n    group_by(sector) |&gt;\n    summarize(proportion = species_harvest[species == \"chinook\"] / sum(species_harvest))\n  \n  # Calculate difference in proportions between sectors\n  pe &lt;- chinook_prop$proportion[2] - chinook_prop$proportion[1]\n  pe\n})\n\n# Visualize null distribution\nggplot(tibble(null_dist), aes(null_dist)) +\n  geom_histogram(bins = 20, color = \"#B8CCE1\", fill = NA, linewidth = 1) +\n  geom_vline(xintercept = pe, color = \"#F0B7B0\", linewidth = 1) +\n  geom_text(aes(x = 0.0105, y = 310, label = paste(\"True Point Estimate\")), \n            color = \"#F0B7B0\", size = 4) +\n  labs(x = \"Null distribution\",\n       y = \"Count\",\n       title = \"Simulated distribution of the sample statistic under the null hypothesis\") +\n  theme_bw()\n\n\n\n\nThis plot shows the simulated distribution of the difference in proportions under the null hypothesis. The pink line shows the true difference in proportions of the sample.\n\n\n\n\nUnder the null hypothesis, the sample statistic is normally distributed and centered around 0. The true point statistic from the data is out to the right.\nStep 4: Calculate probability of the point estimate under the null\n\n# Calculate the p-value\npval &lt;- sum((null_dist) &gt; (pe)) / length(null_dist)\nprint(pval)\n\n[1] 0\n\n\nThe p-value 0 is less than the threshold, 0.05. So, I am able to reject the null hypothesis and say that there is a 0% chance that the relationship is due to random chance. I find that the proportion of Chinook salmon harvested is in fact greater in the subsistence sector than the commercial sector."
  },
  {
    "objectID": "blog-posts/chinook-harvest/index.html#interpretation-and-further-investigation",
    "href": "blog-posts/chinook-harvest/index.html#interpretation-and-further-investigation",
    "title": "Chinook Salmon Harvest",
    "section": "",
    "text": "Limitations:\n\nSubsistence harvest data is an estimate based on household surveys and permit returns. It is extremely difficult to obtain reliable subsistence harvest data in these small communities.\nThe data I use for running the randomization test is highly aggregated, missing nuance that may exist on a finer scale.\n\nThis is an extremely simplified analysis of a very complex system. The results I found, though an interesting starting point for further analysis, should be interpreted for educational purposes only. This workflow was created as the final assignment for the graduate course EDS 222: Statistics for Environmental Data Science in the MEDS program at the Bren School of Environmental Science & Management. Throughout my project, it was my goal to apply concepts and techniques learned in class to a question about a real-world system, not to necessarily draw any reliable scientific conclusions from the study.\nThat said, my results have piqued my interest. What is this suggesting about the way Aleutian communities prioritize cultural significance and monetary incentive? Are we seeing the results of fisherman preferences or fishery sector escapement counts and bag limits? Would I see the same results if I had considered the proportion of Chinook harvested in these fishing sectors over time? What if I added other parts of the system, such as declining Chinook abundance, or Chinook escapement counts from subsistence fisheries? The questions are endless, and the data that SASAP provided is quite comprehensive. Further investigation using these datasets could yield some extremely interesting results, with potentially high value for Unangan people and Aleutian fishing communities.\nNote:\nI switch between talking about Unangan people and the broader Aleutian fishing communities throughout this analysis. Both Indigenous and non-Indigenous residents of the Aleutian Islands and Alaskan Peninsula participate in commercial and subsistence fishing activities, with Indigenous fishers only making up a small portion of the population. Drawing on my personal experience in these tight-knit communities, cultural practices regarding salmon carry across Indigenous and non-Indigenous members alike. Because of this, I take liberties applying “cultural significance” to all community members in the region.\n\nThank you!\n\n\n\n\n\n\n\n\n\n\n\nImage credits: Eric Jablonowski"
  },
  {
    "objectID": "blog-posts/chinook-harvest/index.html#footnotes",
    "href": "blog-posts/chinook-harvest/index.html#footnotes",
    "title": "Chinook Salmon Harvest",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn this section, when possible, I will be using the traditional Aleut language, Unangam Tunuu. All words are translated in the Aleutian Pribilof Islands Associaton’s Traditional Foods Glossary↩︎\nAlaska Department of Fish and Game. (2023). 2023 preliminary Alaska Commercial Harvest and Exvessel Values. https://www.adfg.alaska.gov/static/fishing/pdfs/commercial/2023_preliminary_salmon_summary_table.pdf↩︎\nSASAP. (n.d.). Alaska Peninsula/Aleutian Islands Alaska Peninsula/Aleutian Islands : SASAP : State of Alaska Salmon and People. https://alaskasalmonandpeople.org/region/alaska-peninsula-aleutian-islands/↩︎\nJeanette Clark, & Alaska Department Fish Game, Division Commercial Fisheries Alaska Department Fish Game, Division Sport Fish Alaska Department Fish Game, Division of and of of and of of and of Subsistence. (2019). Harvest of Salmon across Commercial, Subsistence, Personal Use, and Sport Fish sectors, Alaska, 1995-2016. Knowledge Network for Biocomplexity. doi:10.5063/F1HM56Q3.↩︎\nBrendan Connors, Gregory T Ruggerone, James R Irvine, Adapting management of Pacific salmon to a warming and more crowded ocean, ICES Journal of Marine Science, 2024;, fsae135, https://doi.org/10.1093/icesjms/fsae135↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "marina kochuten",
    "section": "",
    "text": "hi!\nI’m Marina. Currently, I am a Masters student in Environmental Data Science at UCSB’s Bren School of Environmental Science & Resource Management. As an emerging data scientist, I am constantly curious, creative, and eager to apply my newly developed skills to ecology and conservation. Outside of my work, you can find me cooking a fresh vegetarian meal, enjoying all things outdoors, and hanging with my pup Tahoma. Poke around my site to learn more about me and my work!\n\n\neducation\nMaster of Environmental Data Science (Expected June 2025)\n\nBren School of Environmental Science & Management | University of California, Santa Barbara (UCSB)\n\nBachelor of Science in Environmental Science & Resource Management (December 2019)\n\nUniversity of Washington (UW), Seattle, WA\nStudy Abroad: Council on International Educational Exchange, Tropical Ecology & Conservation, Costa Rica (January – May 2019)"
  },
  {
    "objectID": "DELETELATER/practice.html",
    "href": "DELETELATER/practice.html",
    "title": "Here is my level one header",
    "section": "",
    "text": "Here is my level one header\nHere is my first paragraph\nHere is my second paragraph, where you can read more about MEDS.\nThis is very important text!"
  },
  {
    "objectID": "blog-posts/thomas-blog/index.html",
    "href": "blog-posts/thomas-blog/index.html",
    "title": "Visualizing the 2017 Thomas Fire: A Python Analysis",
    "section": "",
    "text": "The Thomas Fire, which burned over 280,000 acres in Ventura and Santa Barbara counties in December 2017, was one of California’s largest wildfires at the time. It caused widespread ecological damage, displaced communities, and left lasting environmental impacts.\nUsing NASA’s Landsat data and California Fire Perimeter data, I create a map that visualizes the extent of the Thomas Fire. In conjunction, I use Air Quality Index (AQI) data from the Environmental Protection Agency (EPA) to visualize the AQI surrounding the fire. Together, these visualizations showcase the impact that the Thomas Fire had on the community.\n\n\n\n\n\n\n\n\n\n\n\n\nFor the full analysis, see my GitHub repository.\n\n\n\nRaster manipulation using rioxarray\nVector data manipulation using GeoPandas\nFalse color imagery to highlight wildfire impact\nData visualization with matplotlib\n\n\n\n\nLandsat: I use a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite. The data was retrieved from the Microsoft Planetary Computer data catalogue and pre-processed to remove data outside land and coarsen the spatial resolution. This data is intended for visualization and educational purposes only.\n\nCitation: Microsoft Planetary Computer data catalogue (2024), Landsat Collection 2 Level-2 (simplified) [Data set] Available from: https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Access date: November 18, 2024.\n\nFire perimeters: I use California Fire Perimeter data from the State of California’s Data Catalog to subset to the Thomas Fire boundary. In this analysis, I will be using the file that I created from the full dataset. The dataset is updated annually and includes fire perimeters dating back to 1878.\n\nCitation: State of California Data Catalog (2024), California Fire Perimeters (all) [Data set] Available from: https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436. Access date: November 18, 2024.\n\nAir Quality Index (AQI): The EPA’s AirData tool has pre-generated files of data available for download. The files are updated twice per year: once in June to capture the complete data for the prior year and once in December to capture the data for the summer. AQI is calculated each day for each monitor for the Criteria Gases and PM10 and PM2.5. For this analysis, I use two files, one containing daily AQI data for 2017 and one for 2018.\n\nCitation: Environmental Protection Agency AirData (2024), Daily AQI by County [Data Set] Available from: https://www.epa.gov/outdoor-air-quality-data/download-daily-data. Access date: October 20, 2024."
  },
  {
    "objectID": "blog-posts/thomas-blog/index.html#about",
    "href": "blog-posts/thomas-blog/index.html#about",
    "title": "Visualizing the 2017 Thomas Fire: A Python Analysis",
    "section": "",
    "text": "The Thomas Fire, which burned over 280,000 acres in Ventura and Santa Barbara counties in December 2017, was one of California’s largest wildfires at the time. It caused widespread ecological damage, displaced communities, and left lasting environmental impacts.\nUsing NASA’s Landsat data and California Fire Perimeter data, I create a map that visualizes the extent of the Thomas Fire. In conjunction, I use Air Quality Index (AQI) data from the Environmental Protection Agency (EPA) to visualize the AQI surrounding the fire. Together, these visualizations showcase the impact that the Thomas Fire had on the community.\n\n\n\n\n\n\n\n\n\n\n\n\nFor the full analysis, see my GitHub repository.\n\n\n\nRaster manipulation using rioxarray\nVector data manipulation using GeoPandas\nFalse color imagery to highlight wildfire impact\nData visualization with matplotlib\n\n\n\n\nLandsat: I use a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite. The data was retrieved from the Microsoft Planetary Computer data catalogue and pre-processed to remove data outside land and coarsen the spatial resolution. This data is intended for visualization and educational purposes only.\n\nCitation: Microsoft Planetary Computer data catalogue (2024), Landsat Collection 2 Level-2 (simplified) [Data set] Available from: https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Access date: November 18, 2024.\n\nFire perimeters: I use California Fire Perimeter data from the State of California’s Data Catalog to subset to the Thomas Fire boundary. In this analysis, I will be using the file that I created from the full dataset. The dataset is updated annually and includes fire perimeters dating back to 1878.\n\nCitation: State of California Data Catalog (2024), California Fire Perimeters (all) [Data set] Available from: https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436. Access date: November 18, 2024.\n\nAir Quality Index (AQI): The EPA’s AirData tool has pre-generated files of data available for download. The files are updated twice per year: once in June to capture the complete data for the prior year and once in December to capture the data for the summer. AQI is calculated each day for each monitor for the Criteria Gases and PM10 and PM2.5. For this analysis, I use two files, one containing daily AQI data for 2017 and one for 2018.\n\nCitation: Environmental Protection Agency AirData (2024), Daily AQI by County [Data Set] Available from: https://www.epa.gov/outdoor-air-quality-data/download-daily-data. Access date: October 20, 2024."
  },
  {
    "objectID": "blog-posts/thomas-blog/index.html#mapping-the-fire",
    "href": "blog-posts/thomas-blog/index.html#mapping-the-fire",
    "title": "Visualizing the 2017 Thomas Fire: A Python Analysis",
    "section": "Mapping the fire",
    "text": "Mapping the fire\n\nSetup\nTo start, I set up my analysis by loading all necessary libraries and data files.\n\n# Libraries for general analysis\nimport numpy as np\nimport pandas as pd\n\n# Libraries for geospatial data\nimport geopandas as gpd\nimport rioxarray as rioxr\n\n# Libraries for plotting\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches                # For creating custom legend\nfrom matplotlib_scalebar.scalebar import ScaleBar    # For adding scalebar \n\n# Import Landsat data\nlandsat = rioxr.open_rasterio('data/landsat8-2018-01-26-sb-simplified.nc')\n\n# Import California fire perimeters\nthomas_fire = gpd.read_file('data/thomas_fire_boundary.geojson')\n\n\n\nPrepare Data\nNow, I need to prepare the Landsat data. For processing the Landsat data, I will be primarily working with the rioxarray package. rioxarray is an extension of xarray that focuses on geospatial raster data. By loading the Landsat data in using rioxarray, I load the file as an xarray.Dataset, an object that includes both the raster data and the associated geospatial metadata, including CRS, affine transformations, and spatial coordinates.\n\n# Look at the Landsat raster\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\nTaking a look at the Landsat raster, I notice that we have a dimension named band that contains only one layer.\nUsing squeeze() and drop_vars(), I drop this unnecessary band dimension and it’s associated coordinates, resulting in a simpler, 2-dimensional raster. This will make plotting easier down the line.\n\n# Drop redundant band dimension\nlandsat = landsat.squeeze().drop_vars('band')\n\nNow, the Landsat raster is ready to be plotted.\nTo accentuate the Thomas fire scar, I overlay the Landsat raster with a polygon representing the perimeter of the Thomas Fire. In my full analysis, I prepared the California fire perimeter data by creating a new geospatial object containing only the Thomas Fire perimeter and saved it as thomas_fire_boundary.geojson. When manipulating the fire perimeter data, I used GeoPandas. Building off of the pandas.DataFrame, the core data structure in GeoPandas is the geopandas.GeoDataFrame, which can store geometry columns and perform spatial operations!\nI knew that the California fire perimeter data contains the columns YEAR_ and FIRE_NAME, which were useful for subsetting to the 2017 Thomas Fire. Since geopandas.GeoDataFrames are pandas.DataFrames at their core, I used basic dataframe subsetting to pull out the area of interest.\nFor the purposes of this post, I have only included my subset file. For the full analysis, see my GitHub repository.\n\n\nPlot the Landsat raster using false color and the Thomas Fire perimeter to highlight the extent of the burn\nRemote sensing instruments collect data from wavelengths both within and outside of the visible spectrum. False color imagery uses these non-visible wavelengths to reveal unique aspects that may not be visible otherwise. False color imagery has a wide range of applications, including acting as a useful tool for monitoring wildfire impacts. By assigning infrared bands to visible colors, these images highlight vegetation health, burn severity, and the extent of fire scars.\nIn this case, I use false color imagery to highlight the 2017 Thomas Fire’s burn scar. I use Landsat’s shortwave infrared as red, near infrared as green, and green bands as blue to visualize the burn. Newly burned land reflects strongly in SWIR bands, making the burn scar appear red in my map. The bright green shows vegetation, as it reflects near infrared light very strongly.\nTo do so, I select the shortwave infrared, near infrared, and red variables, convert to array, and plot. By setting the parameter robust = True in the imshow() method, I adjust the display of the image to handle color scaling appropriately by ignoring the outlier RBG values caused by clouds. It fixes contrast issues that cause images to appear bright white.\n\n\nShow code for the false color image\n# Before two spatial object can interact, I must match the CRSs\nthomas_fire = thomas_fire.to_crs(landsat.rio.crs)\nassert thomas_fire.crs == landsat.rio.crs\n\n# Create an object containing the aspect ratio for the landsat map\nratio = landsat.rio.width / landsat.rio.height\n\n# Initialize plot\nfig, ax = plt.subplots(figsize = (9, 9 * ratio))  # Update figure size and aspect\n\n# Remove axis for cleaner map\nax.axis('off')\n\n# Plot false color image highlighting the burn scar\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(robust = True, ax = ax, zorder = 1)\n\n# Add custom legend items for false color image bands\nlegend_swir = mpatches.Patch(color = \"#FA957D\", label = 'Shortwave Infrared (SWIR) \\n - Burned Area')\nlegend_nir = mpatches.Patch(color = \"#62DF59\", label = 'Near Infrared \\n - Vegetation')\n\n# Add legend\nax.legend(handles = [legend_swir, legend_nir], loc = 'upper right', fontsize = 10)\n\n# Add Thomas Fire perimeter\nthomas_fire.plot(ax = ax, \n                 edgecolor = 'firebrick',\n                 color = 'none',\n                 linewidth = 2,\n                 zorder = 2,\n                 legend = True)\n\n# Add fire perimeter label\nax.text(x = 291870, y = 3831700,         # Position coordinates\n        s = \"Thomas Fire \\n Perimeter\",  # Label text\n        fontsize = 10, \n        weight = 'bold',\n        color = 'firebrick',\n        bbox = dict(facecolor = 'white', edgecolor = 'firebrick', alpha = 0.8, pad = 4))   # Box behind text for visibility\n\n# Add plot title\nax.set_title('2017 Thomas Fire (California) Burn Scar using False Color Imagery', fontsize = 16)\n\n# Add scale bar \nscalebar = ScaleBar(1, units='m', location='lower left', length_fraction=0.25, color='black')  \nax.add_artist(scalebar)\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nThis false color image uses the shortwave infrared and near infrared to easily visualize bare ground / burned areas (shown in red) and vegetation (shown in bright green)."
  },
  {
    "objectID": "blog-posts/thomas-blog/index.html#visualizing-aqi",
    "href": "blog-posts/thomas-blog/index.html#visualizing-aqi",
    "title": "Visualizing the 2017 Thomas Fire: A Python Analysis",
    "section": "Visualizing AQI",
    "text": "Visualizing AQI\nNow that I have a map highlighting the extent of the fire, I will make a supplimentary visualization showcasing the AQI surrounding the event. The U.S. Air Quality Index (AQI) is EPA’s tool for communicating about outdoor air quality and health. The AQI includes six categories, each corresponding to a range of index values. The higher the AQI value, the greater the level of air pollution and the greater the health concern. For example, an AQI value of 50 or below represents good air quality, while an AQI value over 300 represents hazardous air quality.\nFor this, I create a line plot showing both the daily AQI and the 5-day average in Santa Barbara County in 2017 and 2018.\n\nSetup\nFirst, I need to download the AQI data. I am accessing the data straight from its its ZIP file link, so I use the pd.read_csv function with the compression='zip' parameter added.\n\n# Load in county level AQI data from 2017 and 2018\naqi = pd.concat([pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip',\n                             compression = 'zip'),\n                 pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip',\n                            compression = 'zip')])\n\n\n\nPrepare data\nNext, I will tidy the data frame by converting the column names to lower snake case, subsetting to Santa Barbara county, and changing the data type of the date column to datetime.\n\n# Convert column names to lower snake case\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_'))\n\n# Make new data frame containing only AQI data for Santa Barbara County\naqi_sb = ((aqi[aqi['county_name'] == \"Santa Barbara\"])\n          .drop(columns = ['state_name', 'county_name', 'state_code', 'county_code'])\n         )\n\n# Convert date column to datetime object and set as the index\naqi_sb.date = pd.to_datetime(aqi_sb.date)\naqi_sb = aqi_sb.set_index('date')\n\n\n\nPlot daily AQI against the 5-day average AQI from 2017-2018\nRolling averages make it easy to identify short-term trends by smoothing out daily fluctuations. pandas makes calculating rolling averages very simple with the pandas.DataFrame.rolling() method. Since I already have a datetime column in my dataframe that includes day, I can pass the argument window = '5D' to .rolling() to specify a 5-day window, that I can then chain mean() to get the 5-day average!\n\n# Add new column containing a rolling 5-day AQI average\naqi_sb['five_day_average'] = aqi_sb['aqi'].rolling(window = '5D').mean()\n\nNow, I am ready to create the AQI plot.\n\n\nShow code for the AQI plot\n# Plot daily AQI against 5-day average ----\n\n# Initialize figure\nfig, ax = plt.subplots(figsize=(9,5))\n\n# Add daily and 5-day average AQI\naqi_sb.five_day_average.plot(ax=ax, color = 'firebrick', zorder = 3)\naqi_sb.aqi.plot(ax=ax, color = 'cornflowerblue', zorder = 2)\n\n# Add AQI labels for unhealthy levels\nax.axhspan(150, 151.5, facecolor = \"dimgrey\", alpha = 0.8)\nax.text(x = pd.to_datetime('2017-01-10'), y = 155, s = 'Unhealthy', color = 'dimgrey')\nax.axhspan(200, 202, facecolor = \"dimgrey\", alpha = 0.8)\nax.text(x = pd.to_datetime('2017-01-10'), y = 205, s = 'Very Unhealthy', color = 'dimgrey')\nax.axhspan(300, 301, facecolor = \"dimgrey\", alpha = 0.8)\nax.text(x = pd.to_datetime('2017-01-10'), y = 305, s = 'Hazardous', color = 'dimgrey')\n\n# Update axis labels and title\nplt.xlabel('Date')\nplt.ylabel('AQI')\nplt.title('AQI during the 2017 Thomas Fire in Santa Barbara County')\n\n# Add legend\nax.legend(labels = ['Daily AQI', '5-day average AQI'])\n\n# Add label indicating the Thomas Fire\nax.axvline(x = pd.to_datetime('2017-12-01'), color = 'dimgrey', linestyle = 'dashed')\nax.text(x = pd.to_datetime('2017-08-25'), y = 255, s = 'Thomas Fire', color = 'dimgrey')\n\n# Update grid lines\nax.grid(axis = 'y', linewidth = 0.2)\n\nplt.show()"
  },
  {
    "objectID": "blog-posts/thomas-blog/index.html#conclusion",
    "href": "blog-posts/thomas-blog/index.html#conclusion",
    "title": "Visualizing the 2017 Thomas Fire: A Python Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nFor this analysis, I bring my newly aquired skills working with tabular and spatial data in Python together to visualize the impact of the 2017 Thomas Fire on Santa Barbara county. Using false color imagery, I highlight the burn scar. Then, I use daily AQI data to create a plot that accompanies the burn scar map."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "my work",
    "section": "",
    "text": "Chinook Salmon Harvest\n\n\nExploring Chinook salmon harvest within commercial and subsistence fishing sectors in the Aleutian Islands\n\n\n\nQuarto\n\n\nMEDS\n\n\nStats\n\n\nRandomization\n\n\n\n\n\n\n\n\n\nJan 9, 2025\n\n\nMarina Kochuten\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing the 2017 Thomas Fire: A Python Analysis\n\n\n\n\n\n\nJupyter\n\n\nMEDS\n\n\nPython\n\n\n\nUsing AQI data and false color imagery to visualize the effects of the Thomas Fire on Santa Barbara county\n\n\n\n\n\nDec 12, 2024\n\n\nMarina Kochuten\n\n\n\n\n\n\nNo matching items"
  }
]